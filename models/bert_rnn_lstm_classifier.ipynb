{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_rnn_lstm_classifier.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMAknwFjhkmiVa3XV9dyT7h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install emoji\n","# !pip install cloud-tpu-client==0.10 torch==1.10.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezQKIbJPA1wf","executionInfo":{"status":"ok","timestamp":1652069120524,"user_tz":-600,"elapsed":7441,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"31f10367-4da2-4ef0-8198-9c93a42bf7f3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZopoAAFhQHOk","executionInfo":{"status":"ok","timestamp":1652069124202,"user_tz":-600,"elapsed":3698,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"outputs":[],"source":["import re\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel, BertConfig\n","import pandas as pd\n","from tqdm import tqdm\n","\n","import copy\n","\n","# import torch_xla\n","# import torch_xla.core.xla_model as xm\n","# import torch_xla.distributed.parallel_loader as pl\n","# import torch_xla.distributed.xla_multiprocessing as xmp\n","# import torch_xla.utils.utils as xu"]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# torch.cuda.empty_cache()"],"metadata":{"id":"4zlM6GLeKIKJ","executionInfo":{"status":"ok","timestamp":1652069124203,"user_tz":-600,"elapsed":17,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7oQCBpU2PX0","executionInfo":{"status":"ok","timestamp":1652069124732,"user_tz":-600,"elapsed":545,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"736df607-ed8f-4a24-8b7e-b3df07142357"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon May  9 04:06:22 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["print(torch.cuda.memory_allocated())\n","print(torch.cuda.memory_reserved())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQCtbDf23LLi","executionInfo":{"status":"ok","timestamp":1652069124733,"user_tz":-600,"elapsed":13,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"d025400c-76b5-42f8-f879-c37f20fad0f0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","0\n"]}]},{"cell_type":"code","source":["bert_model = \"vinai/bertweet-base\"\n","# bert_model = 'bert-base-uncased'\n","# bert_model = 'google/electra-small-discriminator'\n","\n","tokenizer = AutoTokenizer.from_pretrained(bert_model)\n","bert = AutoModel.from_pretrained(bert_model)"],"metadata":{"id":"ap_4pQcUwl27","executionInfo":{"status":"ok","timestamp":1652069130435,"user_tz":-600,"elapsed":5710,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d7be30c0-50bd-4b09-c9a6-0f4c4c3011dc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["class TweetDataset(Dataset):\n","\n","    def __init__(self, path, seq_len, tokenizer=tokenizer, is_test=False):\n","\n","        self.df = pd.read_csv(path, delimiter = '\\t')\n","        self.seq_len = seq_len\n","        self.tokenizer = tokenizer\n","        self.is_test = is_test\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        \n","        tweets = self.df.loc[index, 'text']\n","        \n","        tweets = self.preprocess(tweets)\n","        inputs = self.tokenizer(tweets, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        \n","        input_ids = inputs['input_ids']\n","        attention_mask = inputs['attention_mask']\n","\n","        if not self.is_test:\n","            return input_ids, attention_mask, self.df.loc[index, 'label']\n","        else:\n","            return input_ids, attention_mask\n","    \n","    def preprocess(self, text):\n","        # text = re.sub(r'https?://t.co/[a-zA-Z0-9]+', '', text)\n","        text = text.split('\\n')\n","\n","        if len(text) > self.seq_len:\n","            text = text[:self.seq_len]\n","        elif len(text) < self.seq_len:\n","            text.extend([''] * (self.seq_len - len(text)))\n","\n","        return text"],"metadata":{"id":"3hfk3e8nOmjk","executionInfo":{"status":"ok","timestamp":1652069130437,"user_tz":-600,"elapsed":15,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class RumourDetector(nn.Module):\n","    def __init__(self, num_layers=1, bidirect=False, bert=bert):\n","        super(RumourDetector, self).__init__()\n","        self.num_layers = num_layers\n","        self.bidirect = bidirect\n","        self.bert = bert\n","        self.embed_size = BertConfig.from_pretrained(bert_model).hidden_size\n","        self.hidden_size = self.embed_size // 2\n","\n","        # self.rnn = nn.LSTM(self.embed_size, self.hidden_size, self.num_layers, batch_first=True, bidirectional=self.bidirect)\n","        self.rnn = nn.RNN(self.embed_size, self.hidden_size, self.num_layers, batch_first=True, bidirectional=self.bidirect)\n","\n","        self.out_layer = nn.Sequential(\n","            nn.Linear(self.hidden_size, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, tweets_seqs, attn_masks):\n","        batch_size = tweets_seqs.shape[0]\n","        seq_len = tweets_seqs.shape[1]\n","        input = torch.zeros(batch_size, seq_len, self.embed_size).to(device) \n","\n","        for i, (tweets_seq, attn_mask) in enumerate(zip(tweets_seqs, attn_masks)):\n","            reps = self.bert(tweets_seq, attention_mask=attn_mask).last_hidden_state\n","            cls_rep = reps[:, 0, :]\n","            input[i] = cls_rep\n","            del reps, cls_rep\n","            torch.cuda.empty_cache()\n","\n","        if self.bidirect:\n","            h0 = torch.zeros(2*self.num_layers, batch_size, self.hidden_size).to(device) \n","            # c0 = torch.zeros(2*self.num_layers, batch_size, self.hidden_size).to(device) \n","        else:\n","            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device) \n","            # c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n","\n","        # output, _ = self.rnn(input, (h0, c0))\n","        output, _ = self.rnn(input, h0)\n","\n","        if self.bidirect:\n","            output = output[:, -1, :self.hidden_size] + output[:, -1, self.hidden_size:]\n","        else:\n","            output = output[:, -1, :]\n","\n","        probs = self.out_layer(output)\n","\n","        preds = (probs > 0.5).int()\n","\n","        # del input, output, h0, c0\n","        del input, output, h0\n","        torch.cuda.empty_cache()\n","\n","        return probs.flatten(), preds.flatten()\n"],"metadata":{"id":"WFKfPyauq81q","executionInfo":{"status":"ok","timestamp":1652069130439,"user_tz":-600,"elapsed":16,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def train(train_status, model, optim, epoch_size, train_loader, valid_loader):\n","    loss_fn = nn.BCELoss()\n","    \n","    # max_valid_f1 = 0\n","    for epoch in range(epoch_size):\n","        model.train()\n","        epoch_loss = 0\n","        epoch_acc = 0\n","        tp, fp, fn = 0, 0, 0\n","        train_loop = tqdm(enumerate(train_loader), total=len(train_loader))\n","        train_loop.set_description(f\"Epoch [{epoch+1}/{epoch_size}]\")\n","\n","        for batch, (tweets_seqs, attention_masks, labels) in train_loop:\n","            tweets_seqs = tweets_seqs.to(device)\n","            attention_masks = attention_masks.to(device)\n","            labels = labels.float().to(device)\n","            probs, preds = model(tweets_seqs, attention_masks)\n","            loss = F.binary_cross_entropy(probs, labels)\n","\n","            optim.zero_grad()\n","            loss.backward()\n","            optim.step() \n","\n","            epoch_loss += loss.item()\n","\n","            confusion_vector = preds / labels\n","            tp += torch.sum(confusion_vector == 1).item()\n","            fp += torch.sum(confusion_vector == float('inf')).item()\n","            fn += torch.sum(confusion_vector == 0).item()\n","            train_f1 = f1_score(tp, fp, fn)\n","            epoch_acc += (preds == labels).float().mean().item()\n","\n","            train_loop.set_postfix_str(\n","                'train_loss={:.5f}, train_acc={:.5f}, train_f1={:.5f}'.format(\n","                    epoch_loss/(batch+1), \n","                    epoch_acc/(batch+1),\n","                    train_f1\n","                )\n","            )\n","\n","            del tweets_seqs, attention_masks, labels, confusion_vector\n","            torch.cuda.empty_cache()\n","        \n","            if batch == len(train_loader)-1:\n","                train_f1 = f1_score(tp, fp, fn)\n","                valid_acc, valid_f1 = validate(model, valid_loader)\n","                train_status['checkpoint'][epoch] = copy.deepcopy(model.state_dict())\n","                train_status['valid_acc'].append(valid_acc)\n","                train_status['valid_f1'].append(valid_f1)\n","                train_status['train_loss'].append(epoch_loss/(batch+1))\n","                train_status['train_acc'].append(epoch_acc/(batch+1))\n","                train_loop.set_postfix_str(\n","                    'train_loss={:.5f}, train_acc={:.5f}, train_f1={:.5f}, valid_acc={:.5f}, valid_f1={:.5f}'.format(\n","                        train_status['train_loss'][-1],\n","                        train_status['train_acc'][-1],\n","                        train_f1,\n","                        train_status['valid_acc'][-1],\n","                        train_status['valid_f1'][-1]\n","                    )\n","                )\n","\n","    train_status['checkpoint']['train_status'] = train_status\n","\n","def validate(model, valid_loader):\n","    model.eval()\n","    acc = 0\n","    tp, fp, fn = 0, 0, 0\n","    with torch.no_grad():\n","        for batch, (inputs, attention_masks, labels) in enumerate(valid_loader):\n","            inputs = inputs.to(device)\n","            attention_masks = attention_masks.to(device)\n","            labels = labels.int().to(device)\n","            _, preds = model(inputs, attention_masks)\n","            \n","            confusion_vector = preds / labels\n","            tp += torch.sum(confusion_vector == 1).item()\n","            fp += torch.sum(confusion_vector == float('inf')).item()\n","            fn += torch.sum(confusion_vector == 0).item()\n","\n","            acc += (preds == labels).float().mean()\n","            del inputs, attention_masks, labels, preds\n","            torch.cuda.empty_cache()\n","\n","        f1 = f1_score(tp, fp, fn)\n","\n","    return acc / len(valid_loader), f1\n","\n","def f1_score(tp, fp, fn):\n","    if (tp + fp == 0):\n","            precision = 0\n","    else:\n","        precision = tp / (tp + fp)\n","    \n","    if (tp + fn == 0):\n","        recall = 0\n","    else:\n","        recall = tp / (tp + fn)\n","    \n","    if (precision + recall == 0):\n","        f1 = 0\n","    else:\n","        f1 = (2 * precision * recall) / (precision + recall)\n","    \n","    return f1\n"],"metadata":{"id":"1aMsEQnaE2AN","executionInfo":{"status":"ok","timestamp":1652069130968,"user_tz":-600,"elapsed":543,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive/') "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDOLvXxNNtn1","executionInfo":{"status":"ok","timestamp":1652069132850,"user_tz":-600,"elapsed":1889,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"e9b86067-62a6-4881-da73-0652e8175c87"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["seq_len = 16\n","epoch_size = 10\n","batch_size = 2\n","lr = 3e-5\n","\n","train_set = TweetDataset('/content/gdrive/MyDrive/data/train.csv', seq_len=seq_len)\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n","\n","valid_set = TweetDataset('/content/gdrive/MyDrive/data/dev.csv', seq_len=seq_len)\n","valid_loader = DataLoader(valid_set, batch_size=1, shuffle=True, num_workers=0)\n","\n","test_set = TweetDataset('/content/gdrive/MyDrive/data/test.csv', seq_len=seq_len, is_test=True)\n","test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=0)"],"metadata":{"id":"2Z2lYOoNPvCB","executionInfo":{"status":"ok","timestamp":1652069132852,"user_tz":-600,"elapsed":7,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model = RumourDetector().to(device)\n","optim = torch.optim.AdamW(model.parameters(), lr=lr)\n","train_status = {'train_loss': [], 'train_acc': [], 'valid_acc': [], 'valid_f1': [], \n","                    'checkpoint': {}}\n","train(train_status, model, optim, epoch_size, train_loader, valid_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"id":"_XWSy_nOQ0zX","executionInfo":{"status":"error","timestamp":1652071258300,"user_tz":-600,"elapsed":2125454,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"a0ab6fe5-3762-4814-aebb-5d8a8a6a82a4"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Epoch [1/10]: 100%|██████████| 903/903 [08:48<00:00,  1.71it/s, train_loss=0.53194, train_acc=0.76412, train_f1=0.06987, valid_acc=0.68081, valid_f1=0.31387]\n","Epoch [2/10]: 100%|██████████| 903/903 [08:49<00:00,  1.70it/s, train_loss=0.51719, train_acc=0.76412, train_f1=0.08974, valid_acc=0.77250, valid_f1=0.00000]\n","Epoch [3/10]: 100%|██████████| 903/903 [08:40<00:00,  1.73it/s, train_loss=0.51905, train_acc=0.77630, train_f1=0.12554, valid_acc=0.77250, valid_f1=0.00000]\n","Epoch [4/10]: 100%|██████████| 903/903 [08:49<00:00,  1.71it/s, train_loss=0.52736, train_acc=0.76744, train_f1=0.04977, valid_acc=0.77250, valid_f1=0.00000]\n","Epoch [5/10]:   2%|▏         | 20/903 [00:10<08:03,  1.82it/s, train_loss=0.43811, train_acc=0.85000, train_f1=0.00000]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-f53eddd5332b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m train_status = {'train_loss': [], 'train_acc': [], 'valid_acc': [], 'valid_f1': [], \n\u001b[1;32m      4\u001b[0m                     'checkpoint': {}}\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-f63638d53f84>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_status, model, optim, epoch_size, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["torch.save(train_status['checkpoint'][8], '/content/gdrive/MyDrive/model/tweet_bert_rnn_clf.pt')\n","# torch.save(train_status['checkpoint'], '/content/gdrive/MyDrive/model/train_status.pt')"],"metadata":{"id":"RIWKFm0hbOdR","executionInfo":{"status":"aborted","timestamp":1652071258292,"user_tz":-600,"elapsed":437,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = RumourDetector()\n","model.load_state_dict(torch.load('/content/gdrive/MyDrive/model/tweet_bert_rnn_clf.pt'))\n","model.to(device)"],"metadata":{"id":"8NeqBkDx5J01","executionInfo":{"status":"aborted","timestamp":1652071258295,"user_tz":-600,"elapsed":440,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(model, test_loader):\n","    model.eval()\n","    labels = []\n","    with torch.no_grad():\n","        for batch, (inputs, attention_masks) in enumerate(test_loader):\n","            inputs = inputs.to(device)\n","            attention_masks = attention_masks.to(device)\n","            _, preds = model(inputs, attention_masks)\n","            preds = preds.tolist()\n","            labels.extend(preds)\n","            del inputs, attention_masks, preds\n","            torch.cuda.empty_cache()\n","    df = pd.DataFrame({'Id': list(range(0, len(test_loader))), 'Predicted': labels})\n","    df.to_csv('/content/gdrive/MyDrive/data/test.pred.csv', sep=',', index=False, encoding='utf-8')"],"metadata":{"id":"5Z7GG2mjcKJF","executionInfo":{"status":"aborted","timestamp":1652071258297,"user_tz":-600,"elapsed":442,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test(model, test_loader=test_loader)"],"metadata":{"id":"73D627q0cVrr","executionInfo":{"status":"aborted","timestamp":1652071258299,"user_tz":-600,"elapsed":443,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":null,"outputs":[]}]}