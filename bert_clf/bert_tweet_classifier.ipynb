{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_tweet_classifier.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNki3+9uu8HR3f/IumQdFrT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install emoji\n","# !pip install cloud-tpu-client==0.10 torch==1.10.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezQKIbJPA1wf","executionInfo":{"status":"ok","timestamp":1650976884683,"user_tz":-600,"elapsed":5031,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"cc277868-62be-4419-9ab7-251611d2c104"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZopoAAFhQHOk","executionInfo":{"status":"ok","timestamp":1650976888179,"user_tz":-600,"elapsed":3507,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"outputs":[],"source":["import re\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel, BertConfig\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# import torch_xla\n","# import torch_xla.core.xla_model as xm\n","# import torch_xla.distributed.parallel_loader as pl\n","# import torch_xla.distributed.xla_multiprocessing as xmp\n","# import torch_xla.utils.utils as xu"]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","torch.cuda.empty_cache()\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zlM6GLeKIKJ","executionInfo":{"status":"ok","timestamp":1650976888181,"user_tz":-600,"elapsed":27,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"c0b208b2-434b-4b86-c9e1-37dbe3da3918"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr 26 12:42:22 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P8    14W /  70W |      3MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["bert_model = \"vinai/bertweet-base\"\n","# bert_model = 'bert-base-uncased'"],"metadata":{"id":"ap_4pQcUwl27","executionInfo":{"status":"ok","timestamp":1650976888182,"user_tz":-600,"elapsed":19,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class TweetDataset(Dataset):\n","\n","    def __init__(self, path, bert_model=bert_model, is_test=False):\n","\n","        self.df = pd.read_csv(path, delimiter = '\\t')\n","        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)\n","        self.is_test = is_test\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        \n","        tweets = self.df.loc[index, 'text']\n","        \n","        tweets = self.preprocess(tweets)\n","        inputs = self.tokenizer(tweets, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        \n","        input_ids = inputs['input_ids'][0]\n","        attention_mask = inputs['attention_mask'][0]\n","\n","        if not self.is_test:\n","            return input_ids, attention_mask, self.df.loc[index, 'label']\n","        else:\n","            return input_ids, attention_mask\n","    \n","    def preprocess(self, text):\n","        # text = text.replace('\\n', '</s>')\n","        # text = re.sub(r'https?://t.co/[a-zA-Z0-9]+', '', text)\n","        \n","        return text"],"metadata":{"id":"3hfk3e8nOmjk","executionInfo":{"status":"ok","timestamp":1650976888183,"user_tz":-600,"elapsed":19,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class RumourDetector(nn.Module):\n","    def __init__(self, bert_model=bert_model):\n","        super(RumourDetector, self).__init__()\n","        self.bert_block = AutoModel.from_pretrained(bert_model)\n","\n","        self.clf_block = nn.Sequential(\n","            nn.Dropout(),\n","            nn.Linear(BertConfig.from_pretrained(bert_model).hidden_size, 128),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            nn.Linear(128, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","        # for p in self.bert_block.parameters():\n","        #     p.requires_grad = False\n","\n","    def forward(self, input, attn_mask):\n","        outputs = self.bert_block(input, attention_mask=attn_mask)\n","\n","        cls_rep = outputs.last_hidden_state[:, 0, :]\n","\n","        probs = self.clf_block(cls_rep)\n","        preds = (probs > 0.5).int()\n","\n","        return probs.flatten(), preds.flatten()\n"],"metadata":{"id":"WFKfPyauq81q","executionInfo":{"status":"ok","timestamp":1650976930556,"user_tz":-600,"elapsed":484,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def train(model, optim, epoch_size, train_loader, valid_loader):\n","    loss_fn = nn.BCELoss()\n","    train_status = {'train_loss': [], 'train_acc': [], 'valid_acc': [], \n","                    'checkpoint': {}}\n","    max_valid_acc = 0\n","    for epoch in range(epoch_size):\n","        model.train()\n","        epoch_loss = 0\n","        epoch_acc = 0\n","        train_loop = tqdm(enumerate(train_loader), total=len(train_loader))\n","        train_loop.set_description(f\"Epoch [{epoch+1}/{epoch_size}]\")\n","\n","        for batch, (inputs, attention_masks, labels) in train_loop:\n","            inputs = inputs.to(device)\n","            attention_masks = attention_masks.to(device)\n","            labels = labels.float().to(device)\n","            probs, preds = model(inputs, attention_masks)\n","            loss = F.binary_cross_entropy(probs, labels)\n","\n","            optim.zero_grad()\n","            loss.backward()\n","            optim.step() \n","\n","            epoch_loss += loss.item()\n","            epoch_acc += (preds == labels).float().mean().item()\n","            train_loop.set_postfix_str(\n","                'train_loss={:.3f}, train_acc={:.3f}'.format(\n","                    epoch_loss/(batch+1), epoch_acc/(batch+1)\n","                )\n","            )\n","\n","            del inputs, attention_masks, labels\n","        \n","            if batch == len(train_loader)-1:\n","                valid_acc = validate(model, valid_loader)\n","                if valid_acc > max_valid_acc:\n","                    max_valid_acc = valid_acc\n","                    train_status['checkpoint']['state_dict'] = model.state_dict()\n","                train_status['valid_acc'].append(valid_acc)\n","                train_status['train_loss'].append(epoch_loss/(batch+1))\n","                train_status['train_acc'].append(epoch_acc/(batch+1))\n","                train_loop.set_postfix_str(\n","                    'train_loss={:.3f}, train_acc={:.3f}, valid_acc={:.3f}'.format(\n","                        train_status['train_loss'][-1],\n","                        train_status['train_acc'][-1],\n","                        train_status['valid_acc'][-1]\n","                    )\n","                )\n","\n","    train_status['checkpoint']['train_status'] = train_status\n","    return train_status\n","\n","def validate(model, valid_loader):\n","    model.eval()\n","    acc = 0\n","    for batch, (inputs, attention_masks, labels) in enumerate(valid_loader):\n","        inputs = inputs.to(device)\n","        attention_masks = attention_masks.to(device)\n","        labels = labels.float().to(device)\n","        _, preds = model(inputs, attention_masks)\n","        acc += (preds == labels).float().mean()\n","        del inputs, attention_masks, labels\n","    return acc / len(valid_loader)"],"metadata":{"id":"1aMsEQnaE2AN","executionInfo":{"status":"ok","timestamp":1650976888186,"user_tz":-600,"elapsed":21,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive/') "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDOLvXxNNtn1","executionInfo":{"status":"ok","timestamp":1650976890274,"user_tz":-600,"elapsed":2108,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"5e90ddc8-6c31-44a2-a67d-6dd7ce4179da"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["epoch_size = 10\n","batch_size = 16\n","lr = 1e-5\n","\n","train_set = TweetDataset('/content/gdrive/MyDrive/data/train.csv')\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n","                                           shuffle=True, num_workers=0)\n","\n","valid_set = TweetDataset('/content/gdrive/MyDrive/data/dev.csv')\n","valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, \n","                                           shuffle=True, num_workers=0)\n","\n","test_set = TweetDataset('/content/gdrive/MyDrive/data/test.csv', is_test=True)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, \n","                                           shuffle=False, num_workers=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Z2lYOoNPvCB","executionInfo":{"status":"ok","timestamp":1650976954007,"user_tz":-600,"elapsed":18876,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"393f22bd-d56d-4a09-d0e1-813548374efa"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["model = RumourDetector().to(device)\n","optim = torch.optim.Adam(model.parameters(), lr=lr)\n","train_status = train(model, optim, epoch_size, train_loader, valid_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XWSy_nOQ0zX","executionInfo":{"status":"ok","timestamp":1650977453621,"user_tz":-600,"elapsed":497745,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"5a74360d-1909-48d7-e1f3-357640ef5a69"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Epoch [1/10]: 100%|██████████| 113/113 [00:52<00:00,  2.14it/s, train_loss=0.543, train_acc=0.771, valid_acc=0.773]\n","Epoch [2/10]: 100%|██████████| 113/113 [00:48<00:00,  2.32it/s, train_loss=0.473, train_acc=0.772, valid_acc=0.772]\n","Epoch [3/10]: 100%|██████████| 113/113 [00:49<00:00,  2.30it/s, train_loss=0.429, train_acc=0.796, valid_acc=0.797]\n","Epoch [4/10]: 100%|██████████| 113/113 [00:49<00:00,  2.30it/s, train_loss=0.361, train_acc=0.854, valid_acc=0.803]\n","Epoch [5/10]: 100%|██████████| 113/113 [00:48<00:00,  2.31it/s, train_loss=0.281, train_acc=0.909, valid_acc=0.862]\n","Epoch [6/10]: 100%|██████████| 113/113 [00:49<00:00,  2.30it/s, train_loss=0.220, train_acc=0.937, valid_acc=0.881]\n","Epoch [7/10]: 100%|██████████| 113/113 [00:49<00:00,  2.30it/s, train_loss=0.177, train_acc=0.953, valid_acc=0.879]\n","Epoch [8/10]: 100%|██████████| 113/113 [00:48<00:00,  2.31it/s, train_loss=0.138, train_acc=0.972, valid_acc=0.894]\n","Epoch [9/10]: 100%|██████████| 113/113 [00:48<00:00,  2.31it/s, train_loss=0.104, train_acc=0.984, valid_acc=0.902]\n","Epoch [10/10]: 100%|██████████| 113/113 [00:49<00:00,  2.31it/s, train_loss=0.120, train_acc=0.972, valid_acc=0.897]\n"]}]},{"cell_type":"code","source":["torch.save(train_status['checkpoint'], '/content/gdrive/MyDrive/model/tweet_clf.pt')"],"metadata":{"id":"RIWKFm0hbOdR","executionInfo":{"status":"ok","timestamp":1650977460328,"user_tz":-600,"elapsed":2002,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def test(model, test_loader):\n","    model.eval()\n","    labels = []\n","    for batch, (inputs, attention_masks) in enumerate(test_loader):\n","        inputs = inputs.to(device)\n","        attention_masks = attention_masks.to(device)\n","        _, preds = model(inputs, attention_masks)\n","        preds = preds.tolist()\n","        labels.extend(preds)\n","        del inputs, attention_masks\n","    df = pd.DataFrame({'Id': list(range(0, len(test_loader))), 'Predicted': labels})\n","    df.to_csv('/content/gdrive/MyDrive/data/test.pred.csv', sep=',', index=False, encoding='utf-8')"],"metadata":{"id":"5Z7GG2mjcKJF","executionInfo":{"status":"ok","timestamp":1650977462775,"user_tz":-600,"elapsed":664,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["test(model, test_loader=test_loader)"],"metadata":{"id":"73D627q0cVrr","executionInfo":{"status":"ok","timestamp":1650977474169,"user_tz":-600,"elapsed":9981,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":16,"outputs":[]}]}