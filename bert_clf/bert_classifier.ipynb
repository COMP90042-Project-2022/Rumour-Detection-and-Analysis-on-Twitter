{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_classifier.ipynb","provenance":[{"file_id":"1gNqjJKXqPbI4DyUoBM74F6XaSlYCOAyZ","timestamp":1651431954978}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyP622QsrRpkAMNVp3H2Ho16"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install emoji\n","# !pip install cloud-tpu-client==0.10 torch==1.10.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezQKIbJPA1wf","executionInfo":{"status":"ok","timestamp":1651466710920,"user_tz":-600,"elapsed":11396,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"3a1bcd3e-e6eb-48d7-dd3f-c5974cec07b0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZopoAAFhQHOk","executionInfo":{"status":"ok","timestamp":1651466715659,"user_tz":-600,"elapsed":4751,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"outputs":[],"source":["import re\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel, BertConfig\n","import pandas as pd\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","\n","import copy\n","\n","# import torch_xla\n","# import torch_xla.core.xla_model as xm\n","# import torch_xla.distributed.parallel_loader as pl\n","# import torch_xla.distributed.xla_multiprocessing as xmp\n","# import torch_xla.utils.utils as xu"]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# torch.cuda.empty_cache()"],"metadata":{"id":"4zlM6GLeKIKJ","executionInfo":{"status":"ok","timestamp":1651466715661,"user_tz":-600,"elapsed":32,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7oQCBpU2PX0","executionInfo":{"status":"ok","timestamp":1651466715666,"user_tz":-600,"elapsed":34,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"f5860e62-f956-4f41-b3b6-af2b0c71e105"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon May  2 04:46:09 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   65C    P0    47W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["print(torch.cuda.memory_allocated())\n","print(torch.cuda.memory_reserved())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQCtbDf23LLi","executionInfo":{"status":"ok","timestamp":1651466716152,"user_tz":-600,"elapsed":510,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"a81a6f29-7b7a-4fa2-9567-e1929b70fec5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","0\n"]}]},{"cell_type":"code","source":["bert_model = \"vinai/bertweet-base\"\n","# bert_model = 'bert-base-uncased'\n","# bert_model = 'google/electra-small-discriminator'\n","\n","tokenizer = AutoTokenizer.from_pretrained(bert_model)\n","bert = AutoModel.from_pretrained(bert_model)"],"metadata":{"id":"ap_4pQcUwl27","executionInfo":{"status":"ok","timestamp":1651466721306,"user_tz":-600,"elapsed":5158,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4b4f3c1-dca2-4fec-839d-388b0fc17baf"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["class TweetDataset(Dataset):\n","\n","    def __init__(self, path, tokenizer=tokenizer, is_test=False):\n","\n","        self.df = pd.read_csv(path, delimiter = '\\t')\n","        self.tokenizer = tokenizer\n","        self.is_test = is_test\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        \n","        tweets = self.df.loc[index, 'text']\n","        \n","        tweets = self.preprocess(tweets)\n","        inputs = self.tokenizer(tweets, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        \n","        input_ids = inputs['input_ids'][0]\n","        attention_mask = inputs['attention_mask'][0]\n","\n","        if not self.is_test:\n","            return input_ids, attention_mask, self.df.loc[index, 'label']\n","        else:\n","            return input_ids, attention_mask\n","    \n","    def preprocess(self, text):\n","        text = text.replace('\\n', '')\n","        # text = text.replace('\\n', '</s>')\n","        # text = re.sub(r'https?://t.co/[a-zA-Z0-9]+', '', text)\n","\n","        return text"],"metadata":{"id":"3hfk3e8nOmjk","executionInfo":{"status":"ok","timestamp":1651466721308,"user_tz":-600,"elapsed":18,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class RumourDetector(nn.Module):\n","    def __init__(self, bert=bert):\n","        super(RumourDetector, self).__init__()\n","        self.bert = bert\n","        self.embed_size = BertConfig.from_pretrained(bert_model).hidden_size\n","\n","        self.clf = nn.Sequential(\n","            # nn.Dropout(0.8),\n","            nn.Linear(self.embed_size, self.embed_size),\n","            nn.Dropout(0.7),\n","            nn.Linear(self.embed_size, self.embed_size//2),\n","            nn.Dropout(0.5),\n","            nn.Linear(self.embed_size//2, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, tweets_seqs, attn_masks):\n","        cls_rep = self.bert(tweets_seqs, attention_mask=attn_masks).last_hidden_state[:, 0, :]\n","        probs = self.clf(cls_rep)\n","\n","        preds = (probs > 0.5).int()\n","\n","        del tweets_seqs, cls_rep\n","        torch.cuda.empty_cache()\n","\n","        return probs.flatten(), preds.flatten()\n"],"metadata":{"id":"WFKfPyauq81q","executionInfo":{"status":"ok","timestamp":1651466721310,"user_tz":-600,"elapsed":18,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def train(model, optim, epoch_size, train_loader, valid_loader):\n","    loss_fn = nn.BCELoss()\n","    train_status = {'train_loss': [], 'train_acc': [], 'valid_acc': [], 'valid_f1': [], \n","                    'checkpoint': {}}\n","    max_valid_acc = 0\n","    for epoch in range(epoch_size):\n","        model.train()\n","        epoch_loss = 0\n","        epoch_acc = 0\n","        train_loop = tqdm(enumerate(train_loader), total=len(train_loader))\n","        train_loop.set_description(f\"Epoch [{epoch+1}/{epoch_size}]\")\n","\n","        for batch, (tweets_seqs, attention_masks, labels) in train_loop:\n","            tweets_seqs = tweets_seqs.to(device)\n","            attention_masks = attention_masks.to(device)\n","            labels = labels.float().to(device)\n","            probs, preds = model(tweets_seqs, attention_masks)\n","            loss = F.binary_cross_entropy(probs, labels)\n","\n","            optim.zero_grad()\n","            loss.backward()\n","            optim.step() \n","\n","            epoch_loss += loss.item()\n","            epoch_acc += (preds == labels).float().mean().item()\n","            train_loop.set_postfix_str(\n","                'train_loss={:.5f}, train_acc={:.5f}'.format(\n","                    epoch_loss/(batch+1), epoch_acc/(batch+1)\n","                )\n","            )\n","\n","            del tweets_seqs, attention_masks, labels\n","            torch.cuda.empty_cache()\n","        \n","            if batch == len(train_loader)-1:\n","                valid_acc, valid_f1 = validate(model, valid_loader)\n","                if valid_acc > max_valid_acc:\n","                    max_valid_acc = valid_acc\n","                    train_status['checkpoint']['state_dict'] = copy.deepcopy(model.state_dict())\n","                train_status['valid_acc'].append(valid_acc)\n","                train_status['valid_f1'].append(valid_f1)\n","                train_status['train_loss'].append(epoch_loss/(batch+1))\n","                train_status['train_acc'].append(epoch_acc/(batch+1))\n","                train_loop.set_postfix_str(\n","                    'train_loss={:.5f}, train_acc={:.5f}, valid_acc={:.5f}, valid_f1={:.5f}'.format(\n","                        train_status['train_loss'][-1],\n","                        train_status['train_acc'][-1],\n","                        train_status['valid_acc'][-1],\n","                        train_status['valid_f1'][-1]\n","                    )\n","                )\n","\n","    train_status['checkpoint']['train_status'] = train_status\n","    return train_status\n","\n","def validate(model, valid_loader):\n","    model.eval()\n","    acc = 0\n","    tp, fp, fn = 0, 0, 0\n","    with torch.no_grad():\n","        for batch, (inputs, attention_masks, labels) in enumerate(valid_loader):\n","            inputs = inputs.to(device)\n","            attention_masks = attention_masks.to(device)\n","            labels = labels.int().to(device)\n","            _, preds = model(inputs, attention_masks)\n","            \n","\n","            confusion_vector = preds / labels\n","            tp += torch.sum(confusion_vector == 1).item()\n","            fp += torch.sum(confusion_vector == float('inf')).item()\n","            fn += torch.sum(confusion_vector == 0).item()\n","\n","            acc += (preds == labels).float().mean()\n","            del inputs, attention_masks, labels, preds\n","            torch.cuda.empty_cache()\n","\n","        if (tp + fp == 0):\n","            precision = 0\n","        else:\n","            precision = tp / (tp + fp)\n","        \n","        if (tp + fn == 0):\n","            recall = 0\n","        else:\n","            recall = tp / (tp + fn)\n","        \n","        if (precision + recall == 0):\n","            f1 = 0\n","        else:\n","            f1 = (2 * precision * recall) / (precision + recall)\n","            \n","    return acc / len(valid_loader), f1"],"metadata":{"id":"1aMsEQnaE2AN","executionInfo":{"status":"ok","timestamp":1651466721818,"user_tz":-600,"elapsed":525,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive/') "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDOLvXxNNtn1","executionInfo":{"status":"ok","timestamp":1651466724374,"user_tz":-600,"elapsed":2562,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}},"outputId":"cb637bbe-ba0e-489d-a60e-9eb6c8df4e71"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["epoch_size = 10\n","batch_size = 8\n","lr = 2e-5\n","\n","train_set = TweetDataset('/content/gdrive/MyDrive/data/train.csv')\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n","\n","valid_set = TweetDataset('/content/gdrive/MyDrive/data/dev.csv')\n","valid_loader = DataLoader(valid_set, batch_size=1, shuffle=True, num_workers=0)\n","\n","test_set = TweetDataset('/content/gdrive/MyDrive/data/test.csv', is_test=True)\n","test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=0)"],"metadata":{"id":"2Z2lYOoNPvCB","executionInfo":{"status":"ok","timestamp":1651466724375,"user_tz":-600,"elapsed":16,"user":{"displayName":"s0coRrECT Ur","userId":"05768332687332134567"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model = RumourDetector().to(device)\n","optim = torch.optim.AdamW(model.parameters(), lr=lr)\n","train_status = train(model, optim, epoch_size, train_loader, valid_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XWSy_nOQ0zX","outputId":"cb7e529b-2973-4201-db26-6e1d74eb1206"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Epoch [1/10]: 100%|██████████| 226/226 [01:09<00:00,  3.26it/s, train_loss=0.49770, train_acc=0.77083, valid_acc=0.82173, valid_f1=0.61818]\n","Epoch [2/10]: 100%|██████████| 226/226 [00:54<00:00,  4.17it/s, train_loss=0.42897, train_acc=0.80715, valid_acc=0.73345, valid_f1=0.61800]\n","Epoch [3/10]:  71%|███████   | 160/226 [00:31<00:12,  5.18it/s, train_loss=0.30445, train_acc=0.88121]"]}]},{"cell_type":"code","source":["for batch, (tweets_seqs, attention_masks, labels) in enumerate(train_loader):\n","    tweets_seqs = tweets_seqs.to(device)\n","    attention_masks = attention_masks.to(device)\n","    labels = labels.float().to(device)\n","    probs, preds = model(tweets_seqs, attention_masks) \n","    break"],"metadata":{"id":"gceVzneI6I_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds"],"metadata":{"id":"Lv1iLti_6j_u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels"],"metadata":{"id":"E4Q2h5QX6tG6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# torch.save(train_status['checkpoint'], '/content/gdrive/MyDrive/model/tweet_bert_clf.pt')"],"metadata":{"id":"RIWKFm0hbOdR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = RumourDetector()\n","# model.load_state_dict(torch.load('/content/gdrive/MyDrive/model/tweet_bert_clf.pt')['state_dict'])\n","# model.to(device)"],"metadata":{"id":"8NeqBkDx5J01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(model, test_loader):\n","    model.eval()\n","    labels = []\n","    with torch.no_grad():\n","        for batch, (inputs, attention_masks) in enumerate(test_loader):\n","            inputs = inputs.to(device)\n","            attention_masks = attention_masks.to(device)\n","            _, preds = model(inputs, attention_masks)\n","            preds = preds.tolist()\n","            labels.extend(preds)\n","            del inputs, attention_masks, preds\n","            torch.cuda.empty_cache()\n","    df = pd.DataFrame({'Id': list(range(0, len(test_loader))), 'Predicted': labels})\n","    df.to_csv('/content/gdrive/MyDrive/data/test.pred.csv', sep=',', index=False, encoding='utf-8')"],"metadata":{"id":"5Z7GG2mjcKJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test(model, test_loader=test_loader)"],"metadata":{"id":"73D627q0cVrr"},"execution_count":null,"outputs":[]}]}